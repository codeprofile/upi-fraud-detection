{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ed9a0ff-407d-469a-b5c9-71d0abf345b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:62: SyntaxWarning: invalid escape sequence '\\$'\n",
      "<>:62: SyntaxWarning: invalid escape sequence '\\$'\n",
      "C:\\Users\\HC117BC\\AppData\\Local\\Temp\\ipykernel_32588\\2011165026.py:62: SyntaxWarning: invalid escape sequence '\\$'\n",
      "  df['Amount'] = df['Amount'].replace('[\\$,]', '', regex=True).astype(float)\n",
      "2025-02-25 16:19:46,950 - ERROR - Error loading models: [Errno 2] No such file or directory: 'xgb_model.pkl'\n",
      "2025-02-25 16:20:06,525 - INFO - Data loaded successfully.\n",
      "2025-02-25 16:20:52,694 - INFO - Data merged successfully.\n",
      "C:\\Users\\HC117BC\\AppData\\Local\\Temp\\ipykernel_32588\\2011165026.py:63: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Amount'].fillna(0, inplace=True)\n",
      "C:\\Users\\HC117BC\\AppData\\Local\\Temp\\ipykernel_32588\\2011165026.py:66: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Zip'].fillna(0, inplace=True)\n",
      "C:\\Users\\HC117BC\\AppData\\Local\\Temp\\ipykernel_32588\\2011165026.py:67: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['combined_description'].fillna(\"Unknown\", inplace=True)\n",
      "2025-02-25 16:23:37,376 - INFO - Data balanced using SMOTE.\n",
      "C:\\Users\\HC117BC\\PycharmProjects\\pythonProject\\NPCI\\venv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [16:23:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "2025-02-25 16:30:33,214 - INFO - Models trained and saved successfully.\n",
      "C:\\Users\\HC117BC\\AppData\\Local\\Temp\\ipykernel_32588\\2011165026.py:62: SyntaxWarning: invalid escape sequence '\\$'\n",
      "  df['Amount'] = df['Amount'].replace('[\\$,]', '', regex=True).astype(float)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 170\u001b[0m\n\u001b[0;32m    167\u001b[0m train_models(X_train, y_train)\n\u001b[0;32m    169\u001b[0m \u001b[38;5;66;03m# # Run FastAPI server\u001b[39;00m\n\u001b[1;32m--> 170\u001b[0m \u001b[43muvicorn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0.0.0.0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\pythonProject\\NPCI\\venv\\Lib\\site-packages\\uvicorn\\main.py:579\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(app, host, port, uds, fd, loop, http, ws, ws_max_size, ws_max_queue, ws_ping_interval, ws_ping_timeout, ws_per_message_deflate, lifespan, interface, reload, reload_dirs, reload_includes, reload_excludes, reload_delay, workers, env_file, log_config, log_level, access_log, proxy_headers, server_header, date_header, forwarded_allow_ips, root_path, limit_concurrency, backlog, limit_max_requests, timeout_keep_alive, timeout_graceful_shutdown, ssl_keyfile, ssl_certfile, ssl_keyfile_password, ssl_version, ssl_cert_reqs, ssl_ca_certs, ssl_ciphers, headers, use_colors, app_dir, factory, h11_max_incomplete_event_size)\u001b[0m\n\u001b[0;32m    577\u001b[0m         Multiprocess(config, target\u001b[38;5;241m=\u001b[39mserver\u001b[38;5;241m.\u001b[39mrun, sockets\u001b[38;5;241m=\u001b[39m[sock])\u001b[38;5;241m.\u001b[39mrun()\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 579\u001b[0m         \u001b[43mserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    580\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m    581\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# pragma: full coverage\u001b[39;00m\n",
      "File \u001b[1;32m~\\PycharmProjects\\pythonProject\\NPCI\\venv\\Lib\\site-packages\\uvicorn\\server.py:66\u001b[0m, in \u001b[0;36mServer.run\u001b[1;34m(self, sockets)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, sockets: \u001b[38;5;28mlist\u001b[39m[socket\u001b[38;5;241m.\u001b[39msocket] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39msetup_event_loop()\n\u001b[1;32m---> 66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserve\u001b[49m\u001b[43m(\u001b[49m\u001b[43msockets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msockets\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\Python312\\Lib\\asyncio\\runners.py:190\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(main, debug, loop_factory)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \n\u001b[0;32m    163\u001b[0m \u001b[38;5;124;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;124;03m    asyncio.run(main())\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;66;03m# fail fast with short traceback\u001b[39;00m\n\u001b[1;32m--> 190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    191\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug\u001b[38;5;241m=\u001b[39mdebug, loop_factory\u001b[38;5;241m=\u001b[39mloop_factory) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mrun(main)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import logging\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import uvicorn\n",
    "\n",
    "# Configure logging for debugging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Initialize FastAPI app\n",
    "app = FastAPI()\n",
    "\n",
    "# Define input schema for API requests\n",
    "class TransactionInput(BaseModel):\n",
    "    timestamp: str\n",
    "    amount: float\n",
    "    merchant_name: int\n",
    "    mcc: int\n",
    "\n",
    "# Step 1: Load Data\n",
    "def load_data():\n",
    "    \"\"\"Load transaction and MCC data.\"\"\"\n",
    "    try:\n",
    "        transactions = pd.read_parquet(\"transactions.parquet\")\n",
    "        mcc_data = pd.read_csv(\"mcc_codes.csv\")\n",
    "        logging.info(\"Data loaded successfully.\")\n",
    "        return transactions, mcc_data\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading data: {e}\")\n",
    "        raise\n",
    "\n",
    "# Step 2: Merge Data\n",
    "def merge_data(transactions, mcc_data):\n",
    "    \"\"\"Merge transaction data with MCC descriptions.\"\"\"\n",
    "    try:\n",
    "        # Merge on MCC code\n",
    "        merged_data = pd.merge(transactions, mcc_data, left_on=\"MCC\", right_on=\"mcc\", how=\"left\")\n",
    "        logging.info(\"Data merged successfully.\")\n",
    "        return merged_data\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error merging data: {e}\")\n",
    "        raise\n",
    "\n",
    "# Step 3: Data Preprocessing\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Clean and transform transaction data.\"\"\"\n",
    "    try:\n",
    "        # Convert timestamp to datetime\n",
    "        df['timestamp'] = pd.to_datetime(df['Year'].astype(str) + '-' + df['Month'].astype(str) + '-' + df['Day'].astype(str) + ' ' + df['Time'])\n",
    "        df['transaction_hour'] = df['timestamp'].dt.hour\n",
    "        df['transaction_day'] = df['timestamp'].dt.dayofweek\n",
    "        df['is_weekend'] = df['transaction_day'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "\n",
    "        # Convert amount to numeric and handle missing values\n",
    "        df['Amount'] = df['Amount'].replace('[\\$,]', '', regex=True).astype(float)\n",
    "        df['Amount'].fillna(0, inplace=True)\n",
    "\n",
    "        # Fill missing ZIP and MCC descriptions\n",
    "        df['Zip'].fillna(0, inplace=True)\n",
    "        df['combined_description'].fillna(\"Unknown\", inplace=True)\n",
    "\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in preprocessing: {e}\")\n",
    "        raise\n",
    "\n",
    "# Step 4: Feature Engineering\n",
    "def feature_engineering(df):\n",
    "    \"\"\"Create meaningful features and encode categorical variables.\"\"\"\n",
    "    try:\n",
    "        label_enc = LabelEncoder()\n",
    "        df['merchant_encoded'] = label_enc.fit_transform(df['Merchant Name'].astype(str))\n",
    "        df['mcc_encoded'] = label_enc.fit_transform(df['MCC'].astype(str))\n",
    "\n",
    "        # Create features\n",
    "        features = ['Amount', 'transaction_hour', 'is_weekend', 'merchant_encoded', 'mcc_encoded']\n",
    "\n",
    "        # Encode 'Is Fraud?' column\n",
    "        fraud_mapping = {'Yes': 1, 'No': 0}\n",
    "        if 'Is Fraud?' in df.columns:\n",
    "            df['Is Fraud?'] = df['Is Fraud?'].map(fraud_mapping).fillna(0).astype(int)\n",
    "            target = df['Is Fraud?']\n",
    "        else:\n",
    "            target = pd.Series([0] * len(df))  # Default to non-fraudulent\n",
    "\n",
    "        return df[features], target\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in feature engineering: {e}\")\n",
    "        raise\n",
    "\n",
    "# Step 5: Handle Imbalanced Data\n",
    "def balance_data(X, y):\n",
    "    \"\"\"Balance the dataset using SMOTE.\"\"\"\n",
    "    try:\n",
    "        smote = SMOTE(sampling_strategy=0.2, random_state=42)\n",
    "        X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "        logging.info(\"Data balanced using SMOTE.\")\n",
    "        return X_resampled, y_resampled\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in data balancing: {e}\")\n",
    "        raise\n",
    "\n",
    "# Step 6: Train Models\n",
    "def train_models(X_train, y_train):\n",
    "    \"\"\"Train fraud detection models and save them.\"\"\"\n",
    "    try:\n",
    "        xgb = XGBClassifier(scale_pos_weight=10, use_label_encoder=False, eval_metric='logloss')\n",
    "        xgb.fit(X_train, y_train)\n",
    "        iso_forest = IsolationForest(contamination=0.02, random_state=42)\n",
    "        iso_forest.fit(X_train)\n",
    "\n",
    "        # Save trained models\n",
    "        joblib.dump(xgb, \"xgb_model.pkl\")\n",
    "        joblib.dump(iso_forest, \"isolation_forest.pkl\")\n",
    "        logging.info(\"Models trained and saved successfully.\")\n",
    "        return xgb, iso_forest\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in model training: {e}\")\n",
    "        raise\n",
    "\n",
    "# Load models at startup for API\n",
    "try:\n",
    "    xgb_model = joblib.load(\"xgb_model.pkl\")\n",
    "    iso_forest_model = joblib.load(\"isolation_forest.pkl\")\n",
    "    logging.info(\"Models loaded successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error loading models: {e}\")\n",
    "    xgb_model, iso_forest_model = None, None\n",
    "\n",
    "# Step 7: API for Real-Time Fraud Detection\n",
    "@app.post(\"/predict\")\n",
    "def predict(transaction: TransactionInput):\n",
    "    \"\"\"Predict if a transaction is fraudulent using trained models.\"\"\"\n",
    "    try:\n",
    "        df = pd.DataFrame([transaction.dict()])\n",
    "        df = preprocess_data(df)\n",
    "        X, _ = feature_engineering(df)\n",
    "\n",
    "        xgb_pred = xgb_model.predict(X)[0] if xgb_model else None\n",
    "        iso_pred = iso_forest_model.predict(X)[0] if iso_forest_model else None\n",
    "\n",
    "        return {\"fraud_xgb\": bool(xgb_pred), \"fraud_isolation_forest\": bool(iso_pred)}\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in prediction: {e}\")\n",
    "        raise HTTPException(status_code=500, detail=\"Prediction error.\")\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and preprocess data\n",
    "    transactions, mcc_data = load_data()\n",
    "    merged_data = merge_data(transactions, mcc_data)\n",
    "    processed_data = preprocess_data(merged_data)\n",
    "\n",
    "    # Feature engineering and balancing\n",
    "    X, y = feature_engineering(processed_data)\n",
    "    X_resampled, y_resampled = balance_data(X, y)\n",
    "\n",
    "    # Train-test split and model training\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "    train_models(X_train, y_train)\n",
    "\n",
    "    # # Run FastAPI server\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
